{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU Use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(bool(len(tf.config.list_physical_devices('GPU'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libaries:\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting and Image Display / Manipulation libaries:\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage import morphology, io, color, exposure, img_as_float, transform\n",
    "\n",
    "# Image processing liabries:\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "\n",
    "# General machine learning libaries:\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# Neural Network libaries:\n",
    "import keras\n",
    "from keras import backend \n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.applications.vgg16 import VGG16 as VGG\n",
    "from keras.applications.vgg16 import preprocess_input as VGG_preprocess_input\n",
    "\n",
    "from keras.applications import DenseNet121 as DenseNet\n",
    "from keras.applications.densenet import preprocess_input as DenseNet_preprocess_input\n",
    "\n",
    "from keras.applications import ResNet50V2 as ResNet\n",
    "from keras.applications.resnet import preprocess_input as ResNet_preprocess_input\n",
    "\n",
    "# Explanation libaries:\n",
    "import lime\n",
    "from lime import lime_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directories:\n",
    "data_dir_path = \"../../group/hedge/Data\"\n",
    "data_dir_path = \"../../group/hedge/Data/data\"\n",
    "\n",
    "# Define path to meta data files:\n",
    "train_meta_data = \"../../group/hedge/Data/data/train_split_v3.txt\"\n",
    "test_meta_data = \"../../group/hedge/Data/data/test_split_v3.txt\"\n",
    "\n",
    "# Define directory to save models & metrics into:\n",
    "model_dir_path = \"../results/models\"\n",
    "metric_dir_path = \"../results/metrics\"\n",
    "\n",
    "# Define path to lung segmentation model file:\n",
    "lung_seg_model_path = \"../results/models/trained_model.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images from a data directory:\n",
    "def load_all_images_from_dir(data_dir, target_size):\n",
    "    \n",
    "    image_list = []\n",
    "    for image in os.listdir(data_dir):\n",
    "        \n",
    "        file_typ = image.split(\".\")[-1]\n",
    "        \n",
    "        if (file_typ == \"jpeg\") or (file_typ == \"jpg\") or (file_typ == \"png\"):    \n",
    "            image = load_img(os.path.join(data_dir, image), target_size=target_size)\n",
    "            image_list.append(image)\n",
    "        \n",
    "    return image_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images of a certain type from a directory (according to meta-data .csv-file):\n",
    "def load_type_images_from_dir(data_dir, meta_data_file, label, target_size):\n",
    "    \n",
    "    meta_data_df = pd.read_csv(meta_data_file, sep=\" \")\n",
    "    type_meta_data_df = meta_data_df.loc[meta_data_df['label'] == label]\n",
    "    \n",
    "    type_images_file_name = type_meta_data_df[\"file_name\"].values\n",
    "    \n",
    "    image_list = []\n",
    "    for image in type_images_file_name: # [:5000]: # TODO: Delete \n",
    "        \n",
    "        image = load_img(os.path.join(data_dir, image), target_size=target_size)\n",
    "        image_list.append(image)\n",
    "    \n",
    "    return image_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and transform diffrent image-classes to np-arrays and get class-labels: \n",
    "def get_dp_label_pair(class_image_lists, nr_samples = None, delete_class_image_lists = True):\n",
    "\n",
    "    nr_classes = len(class_image_lists)\n",
    "    \n",
    "    # Get \"nr_samples\" images from each class:\n",
    "    for i in range(0, nr_classes):\n",
    "        \n",
    "        if nr_samples is not None:\n",
    "            class_image_lists[i] = class_image_lists[i][:nr_samples]\n",
    "            \n",
    "    # Get datapoints as np-arrays: \n",
    "    datapoints = []\n",
    "    for j in range(0, nr_classes):   \n",
    "        \n",
    "        for z, current_dp in enumerate(class_image_lists[j]):\n",
    "            \n",
    "            # Convert current image into a np-arry:\n",
    "            current_dp = img_to_array(current_dp, dtype=np.uint8) \n",
    "            current_dp = np.expand_dims(current_dp, axis=0)    \n",
    "            \n",
    "            datapoints.append(current_dp)\n",
    "       \n",
    "            if delete_class_image_lists:\n",
    "                temp = class_image_lists[j][z]\n",
    "                class_image_lists[j][z] = None\n",
    "                del temp\n",
    "    \n",
    "            if z % 100 == 0:\n",
    "                gc.collect()\n",
    "            \n",
    "\n",
    "    datapoints = np.vstack(datapoints)  \n",
    "\n",
    "    # Get the labels from datapoints:\n",
    "    label_list = []\n",
    "    for k in range(0, nr_classes):\n",
    "        \n",
    "        # Set labels for current class to 1 if first class, else set to zero:\n",
    "        if k == 0:\n",
    "            class_labels = np.ones(len(class_image_lists[k]), dtype=np.uint8)\n",
    "        else: \n",
    "            class_labels = np.zeros(len(class_image_lists[k]), dtype=np.uint8)\n",
    "            \n",
    "        for l in range(1, nr_classes):\n",
    "            \n",
    "            if l == k:\n",
    "                class_labels = np.vstack((class_labels, np.ones(len(class_image_lists[k]), dtype=np.uint8)))\n",
    "            else:\n",
    "                class_labels = np.vstack((class_labels, np.zeros(len(class_image_lists[k]), dtype=np.uint8)))\n",
    "        \n",
    "        label_list.append(class_labels)\n",
    "    \n",
    "    # Reshape label arrays:\n",
    "    labels = label_list[0].T\n",
    "    \n",
    "    for ls in label_list[1:]:\n",
    "        labels = np.append(labels, ls.T, axis=0)\n",
    "    \n",
    "    return datapoints, labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images, resize_scale=None, blur_radius=None, deep_copy=True):\n",
    "    \n",
    "    if deep_copy:\n",
    "        preprocessed_images = []\n",
    "    else:\n",
    "        preprocessed_images = images\n",
    "    \n",
    "    if type(images) is not list:\n",
    "        images = [images]\n",
    "        \n",
    "    for z, image in enumerate(images):\n",
    "\n",
    "        if deep_copy:\n",
    "            image = image.copy()\n",
    "        \n",
    "        # Resize images, if specified:\n",
    "        if resize_scale is not None:\n",
    "            image = image.resize(resize_scale)\n",
    "        \n",
    "        # Convert images to greyscale:\n",
    "        image = image.convert('L').convert('RGB')\n",
    "        \n",
    "        # Equalize the image histogram:\n",
    "        image = ImageOps.equalize(image)\n",
    "        \n",
    "        # Use blur, if specified:\n",
    "        if blur_radius is not None:\n",
    "            image = image.filter(ImageFilter.GaussianBlur(radius=blur_radius)) # default radius = 2;\n",
    "        \n",
    "        if deep_copy:\n",
    "            preprocessed_images.append(image)\n",
    "        else:\n",
    "            preprocessed_images[z] = image\n",
    "        \n",
    "    return preprocessed_images\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def segment_lung_area(images, model_path = lung_seg_model_path):\n",
    "    \n",
    "    lung_masks = []\n",
    "    \n",
    "    # Preprocess test data:  \n",
    "    X = []\n",
    "    for image in images:\n",
    "        \n",
    "        temp_image = img_as_float(image)[...,0]\n",
    "        temp_image = transform.resize(temp_image, (256, 256))\n",
    "        temp_image = exposure.equalize_hist(temp_image)\n",
    "        temp_image = np.expand_dims(temp_image, -1)\n",
    "        \n",
    "        X.append(temp_image)\n",
    "        \n",
    "    X = np.array(X)    \n",
    "    X -= X.mean()\n",
    "    X /= X.std()\n",
    "\n",
    "    # Load model\n",
    "    UNet = load_saved_model(model_path)\n",
    "    \n",
    "    i = 0\n",
    "    for xx in ImageDataGenerator(rescale=1.).flow(X, batch_size=1):\n",
    "        \n",
    "        pred_lung_area = UNet.predict(xx)[..., 0].reshape(X[0].shape[:2])\n",
    "        \n",
    "        size = 0.02 * np.prod(xx.shape[1:3])\n",
    "        \n",
    "        pred_lung_area = pred_lung_area > 0.5\n",
    "        pred_lung_area = morphology.remove_small_objects(pred_lung_area, size)\n",
    "        pred_lung_area = morphology.remove_small_holes(pred_lung_area, size)\n",
    "\n",
    "        # Filter pixels in original image with mask: \n",
    "\n",
    "        # [rows, cols] = pr.shape\n",
    "        # color_mask = np.zeros((rows, cols, 3))\n",
    "        # color_mask[pr == 1] = [1, 1, 1]\n",
    "        \n",
    "        lung_masks.append(pred_lung_area)\n",
    "        \n",
    "        i += 1\n",
    "        if i == X.shape[0]:\n",
    "            break\n",
    "            \n",
    "    return lung_masks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_masks_area(masks):\n",
    "    \n",
    "    inverted_masks = []\n",
    "    \n",
    "    for mask in masks:\n",
    "        inverted_masks.append(np.logical_not(mask))\n",
    "        \n",
    "    return inverted_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_lung_area(images, masks):\n",
    "    \n",
    "    masked_images = []\n",
    "    \n",
    "    # inverted_masks = invert_masks_area(masks)\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        \n",
    "        mask = np.zeros_like(image, dtype=bool)\n",
    "        \n",
    "        for j in range(3):\n",
    "            mask[:,:,j] = masks[i].copy()\n",
    "            \n",
    "        image = img_to_array(image)\n",
    "            \n",
    "        image[mask] = 0   \n",
    "        masked_images.append(array_to_img(image))\n",
    "        \n",
    "    return masked_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and Retrain Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefine_model_wo_top(model, input_shape = (224,224,3), nr_classes = 2, fc_layer_structure = [2048, 2048]):\n",
    "\n",
    "    # Define the new input format for the given model (e.g. 3 channels - 224 width x 224 height):\n",
    "    model_input = Input(shape=input_shape, name = 'model_input')\n",
    "    \n",
    "    # Reuse convolutional layer of the given model: \n",
    "    model_output = model(model_input)\n",
    "\n",
    "    # Define new fully connected layer structure:\n",
    "    x = Flatten(name='flatten')(model_output)\n",
    "    \n",
    "    for i, fc_layer_neurons in enumerate(fc_layer_structure): \n",
    "        x = Dense(fc_layer_neurons, activation='relu', name='fc' + str(i))(x)\n",
    "    \n",
    "    x = Dense(nr_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    #Create your own model \n",
    "    new_model = Model(input = model_input, output = x)\n",
    "\n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom weighted categorical crossentropy loss:\n",
    "def weighted_categorical_crossentropy(w):\n",
    "    w = backend.variable(w)\n",
    "        \n",
    "    def loss(y, y_pred):\n",
    "        # Preprocess predictions to enable use in loss:\n",
    "        y_pred /= backend.sum(y_pred, axis=-1, keepdims=True)\n",
    "        y_pred = backend.clip(y_pred, backend.epsilon(), 1 - backend.epsilon())\n",
    "        \n",
    "        # Calculate and return calculated loss:\n",
    "        loss = -backend.sum(y * backend.log(y_pred) * w, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Train model for binary classification (loss = categorical_crossentropy):\n",
    "def train_model(model, x_train, y_train, x_test = None, y_test = None, weighted_loss=None, batch_size = 1, epochs = 10, shuffle = True, optimizer = SGD(lr = 0.0001, decay = 1e-6, momentum = 0.01, nesterov = True)):\n",
    "    \n",
    "    if weighted_loss is None:\n",
    "        model.compile(loss='categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n",
    "    else:\n",
    "        model.compile(loss=weighted_categorical_crossentropy(weighted_loss), optimizer = optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    score = []\n",
    "    if x_test is not None:\n",
    "        history = model.fit(x_train, y_train, validation_data=(x_test,y_test), batch_size = batch_size, epochs = epochs, shuffle = shuffle)\n",
    "        score = model.evaluate(x_test, y_test, batch_size = batch_size)    \n",
    "        \n",
    "    else:\n",
    "        history = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, shuffle = shuffle)\n",
    "        \n",
    "        \n",
    "    return model, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test, label_list = [\"Normal\", \"Pneumonia\"]):\n",
    "    \n",
    "    y_true = [np.argmax(pred) for pred in list(y_test)]\n",
    "    \n",
    "    y_pred_prob = model.predict(x_test)\n",
    "    y_pred = [np.argmax(pred) for pred in list(y_pred_prob)]\n",
    "    \n",
    "    classification_report_results = classification_report(y_true, y_pred, target_names=label_list)\n",
    "    confusion_matrix_results = confusion_matrix(y_true, y_pred)    \n",
    "    \n",
    "    roc_auc_score_result = roc_auc_score(y_true, y_pred_prob, multi_class=\"ovr\")\n",
    "    \n",
    "    weighted_f1_score_results = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    return weighted_f1_score_results, roc_auc_score_result, classification_report_results, confusion_matrix_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_images_for_model(loaded_images, preprocess_input_function = None):\n",
    "    \n",
    "    images = []\n",
    "    for image in loaded_images:\n",
    "    \n",
    "        # Convert the image into a np-array:\n",
    "        image = img_to_array(image)\n",
    "\n",
    "        # Reshape the image array (add first dimension for the batchsize):\n",
    "        image = np.expand_dims(image, axis=0) \n",
    "\n",
    "        # Preprocess the image for the VGG16-model:\n",
    "        if preprocess_input_function is None:\n",
    "            pass\n",
    "        else:\n",
    "            image = preprocess_input_function(image)\n",
    "        \n",
    "        images.append(image)\n",
    "    \n",
    "    images = np.vstack(images)\n",
    "    return images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_xray_image(model, image, label_list = [\"Normal\", \"Pneumonia\"], display_results = False, return_prob = False):\n",
    "    \n",
    "    prepared_image = prepare_images_for_model([image], preprocess_input_function = None)\n",
    "\n",
    "    # Predict class-propabilities for loaded images using the new model:\n",
    "    new_model_predictions_prob = list(model.predict(prepared_image)[0])\n",
    "    predict_model_label = label_list[new_model_predictions_prob.index(max(new_model_predictions_prob))]\n",
    "    \n",
    "    if display_results:\n",
    "        \n",
    "        # Display loaded single image:\n",
    "        imgplot_xray = plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "        # Display top class propabilities from single loaded image: \n",
    "        print(\"Label:\", predict_model_label, \"\\n\")        \n",
    "    \n",
    "    if return_prob:\n",
    "        return predict_model_label, new_model_predictions_prob\n",
    "    else:\n",
    "        return predict_model_label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use LIME to explain predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def explain_predictions(model, explainer, x_dataset, y_labels, nr_samples = None, indecies = None, classes = [\"Normal\", \"Pneumonia\"], num_samples_lime = 1000, num_features_lime = 10, figwidth = 10, figheight = 10, print_explanations = True):\n",
    "\n",
    "    masks = []\n",
    "    masks_pred_labels = []\n",
    "    masks_real_labels = []\n",
    "    \n",
    "    if (nr_samples is None) and (indecies is None):\n",
    "        return -1\n",
    "    \n",
    "    # Get number of classes:\n",
    "    nr_classes = len(classes)\n",
    "    \n",
    "    # If no indecies are given, select \"nr_samples\" samples:\n",
    "    if indecies is None:\n",
    "        indecies = random.sample(range(x_data.shape[0]), nr_samples)\n",
    "    else:\n",
    "        nr_samples = len(indecies)\n",
    "    \n",
    "    if print_explanations:\n",
    "        # Set plot height and width:\n",
    "        fig, ax = plt.subplots(nr_samples, nr_classes + 1, sharex='col', sharey='row')\n",
    "        fig.set_figwidth(figwidth)\n",
    "        fig.set_figheight(figheight)\n",
    "                \n",
    "    xs = [np.array(prepare_images_for_model([x]), dtype=np.uint8)[0] for x in x_dataset]\n",
    "\n",
    "    # Get explanations for all selected images:\n",
    "    for j in range(nr_samples):\n",
    "        explanation = explainer.explain_instance(xs[indecies[j]], model.predict, \n",
    "                                                 top_labels=nr_classes, hide_color=0, num_samples=num_samples_lime)\n",
    "\n",
    "        if print_explanations:\n",
    "            ax[j,0].imshow(xs[indecies[j]])\n",
    "            ax[j,0].set_title(classes[list(y_data[indecies[j]]).index(max(list(y_data[indecies[j]])))])\n",
    "\n",
    "        xs_pred_label, xs_pred_prob = predict_xray_image(model, xs[indecies[j]], label_list = classes, \n",
    "                                                         display_results = False, return_prob = True)\n",
    "        \n",
    "        \n",
    "        if print_explanations:\n",
    "        \n",
    "            for i in range(nr_classes):\n",
    "                temp, mask = explanation.get_image_and_mask(i, positive_only=True, \n",
    "                                                            num_features=num_features_lime, hide_rest=False)\n",
    "\n",
    "                if i == classes.index(xs_pred_label):\n",
    "                    masks.append(mask)\n",
    "                    masks_pred_labels.append(classes.index(xs_pred_label))\n",
    "                    masks_real_labels.append(list(y_labels[j]).index(1))\n",
    "                    \n",
    "                temp = np.array(temp, dtype=np.uint8)\n",
    "\n",
    "                ax[j,i+1].imshow(mark_boundaries(temp, mask))\n",
    "                ax[j,i+1].set_title('p({}) = {:.4f}'.format(classes[i], xs_pred_prob[i]))\n",
    "                \n",
    "        else: \n",
    "            \n",
    "            temp, mask = explanation.get_image_and_mask(classes.index(xs_pred_label), positive_only=True, \n",
    "                                                        num_features=num_features_lime, hide_rest=False)\n",
    "            \n",
    "            masks.append(mask)\n",
    "            masks_pred_labels.append(classes.index(xs_pred_label))\n",
    "            masks_real_labels.append(list(y_labels[j]).index(1))\n",
    "            \n",
    "    return masks, masks_pred_labels, masks_real_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lung_overlay(explanation_masks, lung_segmentation_masks, labels=None):\n",
    "    \n",
    "    overlay_percentages = []\n",
    "    \n",
    "    for i, explanation in enumerate(explanation_masks):\n",
    "    \n",
    "        explanation_area_px_count = np.sum(np.array(explanation, dtype=int))\n",
    "        overlay_area_px_count = np.sum(np.array(np.logical_and(lung_segmentation_masks, explanation), dtype=int))\n",
    "    \n",
    "        overlay_percentages.append(overlay_area_px_count / explanation_area_px_count)\n",
    "        \n",
    "    if labels is not None:\n",
    "        nr_classes = np.max(labels) + 1\n",
    "        overlay_labels_percentages = []\n",
    "        \n",
    "        print(nr_classes)\n",
    "        print(overlay_percentages)\n",
    "        \n",
    "        for j in range(nr_classes):\n",
    "            \n",
    "            label_percentage = np.mean([percentage for k, percentage in enumerate(overlay_percentages) if labels[k] == j])\n",
    "            overlay_labels_percentages.append(label_percentage)\n",
    "            \n",
    "        return overlay_labels_percentages\n",
    "            \n",
    "    return np.mean(overlay_percentages)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Models & Save Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_name):\n",
    "    model.save(file_name)  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "def load_saved_model(file_name):\n",
    "    # Returns a compiled model:\n",
    "    model = load_model(file_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(file_name, model, x_test, y_test, label_list, overlay_metric = None, overlay_label_metric = None):\n",
    "    \n",
    "    w_f1_score, roc_auc, class_report, conf_matrix = evaluate_model(set_model, x_test, y_test, label_list = label_list)\n",
    "\n",
    "    f = open(file_name, \"w+\")\n",
    "    f.write(\"\\nWeighted F1-Score: \" + str(w_f1_score) + \"; ROC Curve and AUC: \" + str(roc_auc))\n",
    "    f.write(\"\\nClassification Report:\\n\\n\" + str(class_report))\n",
    "    f.write(\"\\nConfusion Matrix:\\n\\n\" + str(conf_matrix))\n",
    "   \n",
    "    if overlay_metric is not None:\n",
    "        f.write(\"\\n\\nOverlay Metric: \" + str(overlay_metric))\n",
    "\n",
    "    if overlay_label_metric is not None:\n",
    "        f.write(\"\\nOverlay Classes: \" + str(overlay_label_metric))\n",
    "        \n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline - Classification Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the project focuses on training a model for classifying images as \"normal\", \"pneumonia\" or \"COVID-19\". In addition, an explainer will be used to calculate the areas \"relevant\" to the model that are located in the lung area of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set radom seeds:\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Set the parameters of the following pipeline run:\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Image parameters:\n",
    "nr_train_samples = None\n",
    "nr_test_samples = None \n",
    "\n",
    "image_size = (256, 256)\n",
    "blur_radius_parameter = None # integer: e.g. 2\n",
    "\n",
    "# Model parameters:\n",
    "selected_model = \"ResNet52\" # , \"VGG16\", \"ResNet121\"\n",
    "\n",
    "nr_classes = 3\n",
    "input_shape = (image_size[0],image_size[1],3)\n",
    "fc_layer_structure = [2048, 2048]\n",
    "\n",
    "# Training parameters:\n",
    "shuffle = True\n",
    "batch_size = 1\n",
    "epochs = 3 # 5\n",
    "\n",
    "# Loss parameters:\n",
    "nr_normal = 7966 \n",
    "nr_pneumonia = 5459 \n",
    "nr_covid = 473\n",
    "nr_data_samples = nr_normal + nr_pneumonia + nr_covid \n",
    "\n",
    "weighted_loss = [nr_normal/nr_normal, nr_normal/nr_pneumonia, nr_normal/nr_covid] # None\n",
    "\n",
    "# Evaluation parameters:\n",
    "data_label_list = [\"Normal\", \"Pneumonia\", \"Covid\"]\n",
    "\n",
    "nr_explanation_regions = 3\n",
    "nr_explanation_iter = 10\n",
    "\n",
    "overlay_metric = None\n",
    "overlay_label_metric = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images from train data set:\n",
    "\n",
    "# Get list of images with \"normal\" label:\n",
    "train_normal_image_list_full = load_type_images_from_dir(data_dir_path + \"/train\", train_meta_data, \"normal\", image_size)\n",
    "\n",
    "# Get list of images with \"pneumonia\" label:\n",
    "train_pneumonia_image_list_full = load_type_images_from_dir(data_dir_path + \"/train\", train_meta_data, \"pneumonia\", image_size)\n",
    "\n",
    "# Get list of images with \"COVID-19\" label:\n",
    "train_covid19_image_list_full = load_type_images_from_dir(data_dir_path + \"/train\", train_meta_data, \"COVID-19\", image_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images from test data set:\n",
    "\n",
    "# Get list of images with \"normal\" label:\n",
    "test_normal_image_list_full = load_type_images_from_dir(data_dir_path + \"/test\", test_meta_data, \"normal\", image_size)\n",
    "\n",
    "# Get list of images with \"pneumonia\" label:\n",
    "test_pneumonia_image_list_full = load_type_images_from_dir(data_dir_path + \"/test\", test_meta_data, \"pneumonia\", image_size)\n",
    "\n",
    "# Get list of images with \"COVID-19\" label:\n",
    "test_covid19_image_list_full = load_type_images_from_dir(data_dir_path + \"/test\", test_meta_data, \"COVID-19\", image_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the loaded images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess loaded training images:\n",
    "train_normal_image_list_full = preprocess_images(train_normal_image_list_full, blur_radius=blur_radius_parameter, deep_copy=False)\n",
    "train_pneumonia_image_list_full = preprocess_images(train_pneumonia_image_list_full, blur_radius=blur_radius_parameter, deep_copy=False)\n",
    "train_covid19_image_list_full = preprocess_images(train_covid19_image_list_full, blur_radius=blur_radius_parameter, deep_copy=False)\n",
    "\n",
    "# Preprocess loaded test images:\n",
    "test_normal_image_list_full = preprocess_images(test_normal_image_list_full, blur_radius=blur_radius_parameter, deep_copy=False)\n",
    "test_pneumonia_image_list_full = preprocess_images(test_pneumonia_image_list_full, blur_radius=blur_radius_parameter, deep_copy=False)\n",
    "test_covid19_image_list_full = preprocess_images(test_covid19_image_list_full, blur_radius=blur_radius_parameter, deep_copy=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split images into training and test data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datapoints and labels from images:\n",
    "x_data, y_data = get_dp_label_pair([train_normal_image_list_full, train_pneumonia_image_list_full, train_covid19_image_list_full], nr_samples = nr_train_samples) \n",
    "x_test, y_test = get_dp_label_pair([test_normal_image_list_full, test_pneumonia_image_list_full, test_covid19_image_list_full], nr_samples = nr_test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import save\n",
    "path_to_arrays = \"../results/image_arrays\"\n",
    "\n",
    "save(path_to_arrays + '/x_data_model_1.npy', x_data) \n",
    "save(path_to_arrays + '/y_data_model_1.npy', y_data) \n",
    "\n",
    "save(path_to_arrays + '/x_test_model_1.npy', x_test) \n",
    "save(path_to_arrays + '/y_test_model_1.npy', y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "path_to_arrays = \"../results/image_arrays\"\n",
    "\n",
    "x_data = load(path_to_arrays + '/x_data_model_1.npy')\n",
    "y_data = load(path_to_arrays + '/y_data_model_1.npy')\n",
    "\n",
    "x_test = load(path_to_arrays + '/x_test_model_1.npy')\n",
    "y_test = load(path_to_arrays + '/y_test_model_1.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained Keras CNNs without the fully connected layer weights (trained on imagenet-data):\n",
    "\n",
    "if selected_model is \"VGG16\":\n",
    "    model_wo_top = VGG(weights='imagenet', include_top=False)\n",
    "    \n",
    "elif selected_model is \"ResNet52\":\n",
    "    model_wo_top = ResNet(weights='imagenet', include_top=False)\n",
    "\n",
    "elif selected_model is \"ResNet121\":\n",
    "    model_wo_top = DenseNet(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the loaded pretrained models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_model = redefine_model_wo_top(model = model_wo_top, input_shape = input_shape, nr_classes = nr_classes, fc_layer_structure = fc_layer_structure)\n",
    "set_model, score = train_model(set_model, x_data, y_data, x_test = x_test, y_test = y_test, weighted_loss = weighted_loss, batch_size = batch_size, epochs = epochs, shuffle = shuffle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the loaded pretrained models on the test data set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_f1_score, roc_auc, class_report, conf_matrix = evaluate_model(set_model, x_test, y_test, label_list = data_label_list)\n",
    "\n",
    "print(\"\\nWeighted F1-Score:\", w_f1_score, \"; ROC Curve and AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\\n\\n\", class_report)\n",
    "print(\"\\nConfusion Matrix:\\n\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an explainer (= LIME) to create masks of relevant areas for each (preprocessed) test image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LIME-Explainer Instance:\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "# Set specific indecies:\n",
    "indecies = list(range(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Explanations for the trained Model:\n",
    "explanation_masks, explanation_masks_pred_labels, explanation_masks_real_labels = explain_predictions(\n",
    "                                                set_model, explainer, x_test, y_test, indecies = indecies, classes = data_label_list, \n",
    "                                                num_features_lime = nr_explanation_regions, num_samples_lime = nr_explanation_iter,\n",
    "                                                figheight = 10, figwidth = 15, print_explanations = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load (non preprocessed) test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get (new not preprocessed) images from test data set:\n",
    "test_normal_image_list_full_for_lg = load_type_images_from_dir(data_dir_path + \"/test\", test_meta_data, \"normal\", image_size)\n",
    "test_pneumonia_image_list_full_for_lg = load_type_images_from_dir(data_dir_path + \"/test\", test_meta_data, \"pneumonia\", image_size)\n",
    "test_covid19_image_list_full_for_lg = load_type_images_from_dir(data_dir_path + \"/test\", test_meta_data, \"COVID-19\", image_size)\n",
    "\n",
    "test_images = test_normal_image_list_full_for_lg + test_pneumonia_image_list_full_for_lg + test_covid19_image_list_full_for_lg\n",
    "test_labels = [0] * len(test_normal_image_list_full_for_lg) + [1] * len(test_pneumonia_image_list_full_for_lg) + [2] * len(test_covid19_image_list_full_for_lg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pretrained lung segmentation model to create masks of lung areas for each (preprocessed) test image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_masks_test_images = segment_lung_area(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the overlay area: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_metric = calculate_lung_overlay(explanation_masks, lung_masks_test_images, labels=None)\n",
    "overlay_label_metric = calculate_lung_overlay(explanation_masks, lung_masks_test_images, labels=test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOverlay Metric:\", overlay_metric)\n",
    "print(\"\\nOverlay Classes:\", overlay_label_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store trained model in the model directory and store evaluation metrics in the metrics directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained Keras-Models:\n",
    "\n",
    "if selected_model is \"VGG16\":\n",
    "    save_model(set_model, model_dir_path + '/' + \"vgg_model.h5\")\n",
    "    save_metrics(metric_dir_path +  '/' + \"vgg_metrics.txt\", set_model, x_test, y_test, data_label_list, overlay_metric = overlay_metric, overlay_label_metric = overlay_label_metric)\n",
    "    \n",
    "elif selected_model is \"ResNet52\":\n",
    "    save_model(set_model, model_dir_path + '/' + \"resnet_model.h5\")\n",
    "    save_metrics(metric_dir_path +  '/' + \"resnet_metrics.txt\", set_model, x_test, y_test, data_label_list, overlay_metric = overlay_metric, overlay_label_metric = overlay_label_metric)\n",
    "    \n",
    "elif selected_model is \"ResNet121\":\n",
    "    save_model(set_model, model_dir_path + '/' + \"densenet_model.h5\")\n",
    "    save_metrics(metric_dir_path +  '/' + \"densenet_metrics.txt\", set_model, x_test, y_test, data_label_list, overlay_metric = overlay_metric, overlay_label_metric = overlay_label_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline - Evaluation Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set radom seeds:\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Set the parameters of the following pipeline run:\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Image parameters:\n",
    "nr_train_samples = None\n",
    "nr_test_samples = None \n",
    "\n",
    "image_size = (256, 256)\n",
    "blur_radius_parameter = None # integer: e.g. 2\n",
    "\n",
    "# Model parameters:\n",
    "selected_model = \"VGG16\" # ,\"ResNet52\", \"ResNet121\"\n",
    "\n",
    "nr_classes = 3\n",
    "input_shape = (image_size[0],image_size[1],3)\n",
    "fc_layer_structure = [2048, 2048]\n",
    "\n",
    "# Training parameters:\n",
    "shuffle = True\n",
    "batch_size = 1\n",
    "epochs = 5\n",
    "\n",
    "# Loss parameters:\n",
    "weighted_loss = None\n",
    "\n",
    "# Evaluation parameters:\n",
    "data_label_list = [\"Normal\", \"Pneumonia\", \"Covid\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images from train data set:\n",
    "\n",
    "# Get list of images with \"normal\" label:\n",
    "train_normal_image_list_full = load_type_images_from_dir(data_dir_path + \"/train\", train_meta_data, \"normal\", image_size)\n",
    "\n",
    "# Get list of images with \"pneumonia\" label:\n",
    "train_pneumonia_image_list_full = load_type_images_from_dir(data_dir_path + \"/train\", train_meta_data, \"pneumonia\", image_size)\n",
    "\n",
    "# Get list of images with \"COVID-19\" label:\n",
    "train_covid19_image_list_full = load_type_images_from_dir(data_dir_path + \"/train\", train_meta_data, \"COVID-19\", image_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images from test data set:\n",
    "\n",
    "# Get list of images with \"normal\" label:\n",
    "test_normal_image_list_full = load_type_images_from_dir(data_dir_path + \"/test\", test_meta_data, \"normal\", image_size)\n",
    "\n",
    "# Get list of images with \"pneumonia\" label:\n",
    "test_pneumonia_image_list_full = load_type_images_from_dir(data_dir_path + \"/test\", test_meta_data, \"pneumonia\", image_size)\n",
    "\n",
    "# Get list of images with \"COVID-19\" label:\n",
    "test_covid19_image_list_full = load_type_images_from_dir(data_dir_path + \"/test\", test_meta_data, \"COVID-19\", image_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pretrained lung segmentation model to create masks of lung areas for each (non preprocessed) train & test image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_train_normal_image_list_full = segment_lung_area(train_normal_image_list_full)\n",
    "masked_train_pneumonia_image_list_full = segment_lung_area(train_pneumonia_image_list_full)\n",
    "masked_train_covid19_image_list_full = segment_lung_area(train_covid19_image_list_full)\n",
    "\n",
    "masked_test_normal_image_list_full = segment_lung_area(test_normal_image_list_full)\n",
    "masked_test_pneumonia_image_list_full = segment_lung_area(test_pneumonia_image_list_full)\n",
    "masked_test_covid19_image_list_full = segment_lung_area(test_covid19_image_list_full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the loaded images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess loaded training images:\n",
    "train_normal_image_list_full = preprocess_images(train_normal_image_list_full, blur_radius=blur_radius_parameter, deep_copy=False)\n",
    "train_pneumonia_image_list_full = preprocess_images(train_pneumonia_image_list_full, blur_radius=blur_radius_parameter, deep_copy=False)\n",
    "train_covid19_image_list_full = preprocess_images(train_covid19_image_list_full, blur_radius=blur_radius_parameter, deep_copy=False)\n",
    "\n",
    "# Preprocess loaded test images:\n",
    "test_normal_image_list_full = preprocess_images(test_normal_image_list_full, blur_radius=blur_radius_parameter, deep_copy=False)\n",
    "test_pneumonia_image_list_full = preprocess_images(test_pneumonia_image_list_full, blur_radius=blur_radius_parameter, deep_copy=False)\n",
    "test_covid19_image_list_full = preprocess_images(test_covid19_image_list_full, blur_radius=blur_radius_parameter, deep_copy=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask lung areas of preprocessed images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_image_list_full = mask_lung_area(train_normal_image_list_full, masked_train_normal_image_list_full)\n",
    "train_pneumonia_image_list_full = mask_lung_area(train_pneumonia_image_list_full, masked_train_pneumonia_image_list_full)\n",
    "train_covid19_image_list_full = mask_lung_area(train_normal_image_list_full, masked_train_normal_image_list_full)\n",
    "\n",
    "test_normal_image_list_full = mask_lung_area(test_pneumonia_image_list_full, masked_test_normal_image_list_full)\n",
    "test_pneumonia_image_list_full = mask_lung_area(test_pneumonia_image_list_full, masked_test_pneumonia_image_list_full)\n",
    "test_covid19_image_list_full = mask_lung_area(test_covid19_image_list_full, masked_test_covid19_image_list_full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split images into training and test data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train-test-split:\n",
    "normal_image_list_full = [train_normal_image_list_full, test_normal_image_list_full]\n",
    "pneumonia_image_list_full = [train_pneumonia_image_list_full, test_pneumonia_image_list_full]\n",
    "covid19_image_list_full = [train_covid19_image_list_full, test_covid19_image_list_full]\n",
    "\n",
    "# Combine lists of diffrent class images into single test/train list:\n",
    "train_combined_lists_full = [normal_image_list_full[0], pneumonia_image_list_full[0], covid19_image_list_full[0]]\n",
    "test_combined_lists_full = [normal_image_list_full[1], pneumonia_image_list_full[1], covid19_image_list_full[1]]\n",
    "\n",
    "# Get datapoints and labels from images:\n",
    "x_data, y_data = get_dp_label_pair(train_combined_lists_full, nr_samples = nr_train_samples) \n",
    "x_test, y_test = get_dp_label_pair(test_combined_lists_full, nr_samples = nr_test_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained Keras CNNs without the fully connected layer weights (trained on imagenet-data):\n",
    "\n",
    "if selected_model is \"VGG16\":\n",
    "    model_wo_top = VGG(weights='imagenet', include_top=False)\n",
    "    \n",
    "elif selected_model is \"ResNet52\":\n",
    "    model_wo_top = ResNet(weights='imagenet', include_top=False)\n",
    "\n",
    "elif selected_model is \"ResNet121\":\n",
    "    model_wo_top = DenseNet(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the loaded pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_model = redefine_model_wo_top(model = model_wo_top, input_shape = input_shape, nr_classes = nr_classes, fc_layer_structure = fc_layer_structure)\n",
    "set_model, score = train_model(set_model, x_data, y_data, x_test = x_test, y_test = y_test, weighted_loss = weighted_loss, batch_size = batch_size, epochs = epochs, shuffle = shuffle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the loaded pretrained models on the test data set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_f1_score, roc_auc, class_report, conf_matrix = evaluate_model(set_model, x_test, y_test, label_list = data_label_list)\n",
    "\n",
    "print(\"\\nWeighted F1-Score:\", w_f1_score, \"; ROC Curve and AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\\n\\n\", class_report)\n",
    "print(\"\\nConfusion Matrix:\\n\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store trained model in the model directory and store evaluation metrics in the metrics directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained Keras-Models:\n",
    "\n",
    "if selected_model is \"VGG16\":\n",
    "    save_model(set_model, model_dir_path + '/' + \"vgg_evaluation_model.h5\")\n",
    "    save_metrics(metric_dir_path +  '/' + \"vgg_evaluation_metrics.txt\", set_model, x_test, y_test, data_label_list)\n",
    "    \n",
    "elif selected_model is \"ResNet52\":\n",
    "    save_model(set_model, model_dir_path + '/' + \"resnet_evaluation_model.h5\")\n",
    "    save_metrics(metric_dir_path +  '/' + \"resnet_evaluation_metrics.txt\", set_model, x_test, y_test, data_label_list)\n",
    "    \n",
    "elif selected_model is \"ResNet121\":\n",
    "    save_model(set_model, model_dir_path + '/' + \"densenet_evaluation_model.h5\")\n",
    "    save_metrics(metric_dir_path +  '/' + \"densenet_evaluation_metrics.txt\", set_model, x_test, y_test, data_label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-GPU",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
