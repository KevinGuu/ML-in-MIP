{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU Use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(bool(len(tf.config.list_physical_devices('GPU'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libaries:\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting and Image Display / Manipulation libaries:\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage import morphology, io, color, exposure, img_as_float, transform\n",
    "\n",
    "# Image processing liabries:\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "\n",
    "# General machine learning libaries:\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# Neural Network libaries:\n",
    "import keras\n",
    "from keras import backend \n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.applications.vgg16 import VGG16 as VGG\n",
    "from keras.applications.vgg16 import preprocess_input as VGG_preprocess_input\n",
    "\n",
    "from keras.applications import DenseNet121 as DenseNet\n",
    "from keras.applications.densenet import preprocess_input as DenseNet_preprocess_input\n",
    "\n",
    "from keras.applications import ResNet50V2 as ResNet\n",
    "from keras.applications.resnet import preprocess_input as ResNet_preprocess_input\n",
    "\n",
    "# Explanation libaries:\n",
    "import lime\n",
    "from lime import lime_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directories:\n",
    "data_dir_path = \"../../group/hedge/Data\"\n",
    "\n",
    "# Define directory to save models into:\n",
    "model_dir_path = \"../results/models\"\n",
    "\n",
    "# Define path to lung segmentation model file:\n",
    "lung_seg_model_path = \"../results/models/trained_model.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images from a data directory:\n",
    "def load_all_images_from_dir(data_dir, target_size):\n",
    "    \n",
    "    image_list = []\n",
    "    for image in os.listdir(data_dir):\n",
    "        \n",
    "        file_typ = image.split(\".\")[-1]\n",
    "        \n",
    "        if (file_typ == \"jpeg\") or (file_typ == \"jpg\") or (file_typ == \"png\"):    \n",
    "            image = load_img(os.path.join(data_dir, image), target_size=target_size)\n",
    "            image_list.append(image)\n",
    "        \n",
    "    return image_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and transform diffrent image-classes to np-arrays and get class-labels: \n",
    "def get_dp_label_pair(class_image_lists, nr_samples = None):\n",
    "\n",
    "    nr_classes = len(class_image_lists)\n",
    "    \n",
    "    # Get \"nr_samples\" images from each class:\n",
    "    for i in range(0, nr_classes):\n",
    "        \n",
    "        if nr_samples is not None:\n",
    "            class_image_lists[i] = class_image_lists[i][:nr_samples]\n",
    "        \n",
    "    # Get datapoints as np-arrays: \n",
    "    datapoints = []\n",
    "    for j in range(0, nr_classes):    \n",
    "        for current_dp in class_image_lists[j]:\n",
    "            \n",
    "            # Convert current image into a np-arry:\n",
    "            current_dp = img_to_array(current_dp)\n",
    "            current_dp = np.expand_dims(current_dp, axis=0)    \n",
    "            \n",
    "            datapoints.append(current_dp)\n",
    "            \n",
    "    datapoints = np.vstack(datapoints)\n",
    "    \n",
    "    # Get the labels from datapoints:\n",
    "    label_list = []\n",
    "    for k in range(0, nr_classes):\n",
    "        \n",
    "        # Set labels for current class to 1 if first class, else set to zero:\n",
    "        if k == 0:\n",
    "            class_labels = np.ones(len(class_image_lists[k]))\n",
    "        else: \n",
    "            class_labels = np.zeros(len(class_image_lists[k]))\n",
    "            \n",
    "        for l in range(1, nr_classes):\n",
    "            \n",
    "            if l == k:\n",
    "                class_labels = np.vstack((class_labels, np.ones(len(class_image_lists[l]))))\n",
    "            else:\n",
    "                class_labels = np.vstack((class_labels, np.zeros(len(class_image_lists[l]))))\n",
    "        \n",
    "        label_list.append(class_labels)\n",
    "    \n",
    "    # Reshape label arrays:\n",
    "    labels = label_list[0].T\n",
    "    \n",
    "    for ls in label_list[1:]:\n",
    "        labels = np.append(labels, ls.T, axis=0)\n",
    "    \n",
    "    return datapoints, labels    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images, resize_scale=None, blur_radius=None, deep_copy=True):\n",
    "    \n",
    "    if deep_copy:\n",
    "        preprocessed_images = []\n",
    "    else:\n",
    "        preprocessed_images = images\n",
    "    \n",
    "    if type(images) is not list:\n",
    "        images = [images]\n",
    "        \n",
    "    for z, image in enumerate(images):\n",
    "\n",
    "        if deep_copy:\n",
    "            image = image.copy()\n",
    "        \n",
    "        # Resize images, if specified:\n",
    "        if resize_scale is not None:\n",
    "            image = image.resize(resize_scale)\n",
    "        \n",
    "        # Convert images to greyscale:\n",
    "        image = image.convert('L').convert('RGB')\n",
    "        \n",
    "        # Equalize the image histogram:\n",
    "        image = ImageOps.equalize(image)\n",
    "        \n",
    "        # Use blur, if specified:\n",
    "        if blur_radius is not None:\n",
    "            image = image.filter(ImageFilter.GaussianBlur(radius=blur_radius)) # default radius = 2;\n",
    "        \n",
    "        if deep_copy:\n",
    "            preprocessed_images.append(image)\n",
    "        else:\n",
    "            preprocessed_images[z] = image\n",
    "        \n",
    "    return preprocessed_images\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def segment_lung_area(images, model_path = lung_seg_model_path):\n",
    "    \n",
    "    lung_masks = []\n",
    "    \n",
    "    # Preprocess test data:  \n",
    "    X = []\n",
    "    for image in images:\n",
    "        \n",
    "        temp_image = img_as_float(image)[...,0]\n",
    "        temp_image = transform.resize(temp_image, (256, 256))\n",
    "        temp_image = exposure.equalize_hist(temp_image)\n",
    "        temp_image = np.expand_dims(temp_image, -1)\n",
    "        \n",
    "        X.append(temp_image)\n",
    "        \n",
    "    X = np.array(X)    \n",
    "    X -= X.mean()\n",
    "    X /= X.std()\n",
    "\n",
    "    # Load model\n",
    "    UNet = load_model(model_path)\n",
    "    \n",
    "    i = 0\n",
    "    for xx in ImageDataGenerator(rescale=1.).flow(X, batch_size=1):\n",
    "        \n",
    "        pred_lung_area = UNet.predict(xx)[..., 0].reshape(X[0].shape[:2])\n",
    "        \n",
    "        size = 0.02 * np.prod(xx.shape[1:3])\n",
    "        \n",
    "        pred_lung_area = pred_lung_area > 0.5\n",
    "        pred_lung_area = morphology.remove_small_objects(pred_lung_area, size)\n",
    "        pred_lung_area = morphology.remove_small_holes(pred_lung_area, size)\n",
    "\n",
    "        # Filter pixels in original image with mask: \n",
    "\n",
    "        # [rows, cols] = pr.shape\n",
    "        # color_mask = np.zeros((rows, cols, 3))\n",
    "        # color_mask[pr == 1] = [1, 1, 1]\n",
    "        \n",
    "        lung_masks.append(pred_lung_area)\n",
    "        \n",
    "        i += 1\n",
    "        if i == X.shape[0]:\n",
    "            break\n",
    "            \n",
    "    return lung_masks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and Retrain Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefine_model_wo_top(model, input_shape = (224,224,3), nr_classes = 2, fc_layer_structure = [2048, 2048]):\n",
    "\n",
    "    # Define the new input format for the given model (e.g. 3 channels - 224 width x 224 height):\n",
    "    model_input = Input(shape=input_shape, name = 'model_input')\n",
    "    \n",
    "    # Reuse convolutional layer of the given model: \n",
    "    model_output = model(model_input)\n",
    "\n",
    "    # Define new fully connected layer structure:\n",
    "    x = Flatten(name='flatten')(model_output)\n",
    "    \n",
    "    for i, fc_layer_neurons in enumerate(fc_layer_structure): \n",
    "        x = Dense(fc_layer_neurons, activation='relu', name='fc' + str(i))(x)\n",
    "    \n",
    "    x = Dense(nr_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    #Create your own model \n",
    "    new_model = Model(input = model_input, output = x)\n",
    "\n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom weighted categorical crossentropy loss:\n",
    "def weighted_categorical_crossentropy(w):\n",
    "    w = backend.variable(w)\n",
    "        \n",
    "    def loss(y, y_pred):\n",
    "        # Preprocess predictions to enable use in loss:\n",
    "        y_pred /= backend.sum(y_pred, axis=-1, keepdims=True)\n",
    "        y_pred = backend.clip(y_pred, backend.epsilon(), 1 - backend.epsilon())\n",
    "        \n",
    "        # Calculate and return calculated loss:\n",
    "        loss = -backend.sum(y * backend.log(y_pred) * w, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Train model for binary classification (loss = categorical_crossentropy):\n",
    "def train_model(model, x_train, y_train, x_test = None, y_test = None, weighted_loss=None, batch_size = 1, epochs = 10, shuffle = True, optimizer = SGD(lr = 0.0001, decay = 1e-6, momentum = 0.01, nesterov = True)):\n",
    "    \n",
    "    if weighted_loss is None:\n",
    "        model.compile(loss='categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n",
    "    else:\n",
    "        model.compile(loss=weighted_categorical_crossentropy(weighted_loss), optimizer = optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    score = []\n",
    "    if x_test is not None:\n",
    "        history = model.fit(x_train, y_train, validation_data=(x_test,y_test), batch_size = batch_size, epochs = epochs, shuffle = shuffle)\n",
    "        score = model.evaluate(x_test, y_test, batch_size = batch_size)    \n",
    "        \n",
    "    else:\n",
    "        history = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, shuffle = shuffle)\n",
    "        \n",
    "        \n",
    "    return model, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test, label_list = [\"Normal\", \"Pneumonia\"]):\n",
    "    \n",
    "    y_true = [np.argmax(pred) for pred in list(y_test)]\n",
    "    \n",
    "    y_pred_prob = vgg_model.predict(x_test)\n",
    "    y_pred = [np.argmax(pred) for pred in list(y_pred_prob)]\n",
    "    \n",
    "    classification_report_results = classification_report(y_true, y_pred, target_names=label_list)\n",
    "    confusion_matrix_results = confusion_matrix(y_true, y_pred)    \n",
    "    \n",
    "    roc_auc_score_result = roc_auc_score(y_true, y_pred_prob, multi_class=\"ovr\")\n",
    "    \n",
    "    weighted_f1_score_results = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    return weighted_f1_score_results, roc_auc_score_result, classification_report_results, confusion_matrix_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_images_for_model(loaded_images, preprocess_input_function = None):\n",
    "    \n",
    "    images = []\n",
    "    for image in loaded_images:\n",
    "    \n",
    "        # Convert the image into a np-array:\n",
    "        image = img_to_array(image)\n",
    "\n",
    "        # Reshape the image array (add first dimension for the batchsize):\n",
    "        image = np.expand_dims(image, axis=0) \n",
    "\n",
    "        # Preprocess the image for the VGG16-model:\n",
    "        if preprocess_input_function is None:\n",
    "            pass\n",
    "        else:\n",
    "            image = preprocess_input_function(image)\n",
    "        \n",
    "        images.append(image)\n",
    "    \n",
    "    images = np.vstack(images)\n",
    "    return images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_xray_image(model, image, label_list = [\"Normal\", \"Pneumonia\"], display_results = False, return_prob = False):\n",
    "    \n",
    "    prepared_image = prepare_images_for_model([image], preprocess_input_function = None)\n",
    "\n",
    "    # Predict class-propabilities for loaded images using the new model:\n",
    "    new_model_predictions_prob = list(model.predict(prepared_image)[0])\n",
    "    predict_model_label = label_list[new_model_predictions_prob.index(max(new_model_predictions_prob))]\n",
    "    \n",
    "    if display_results:\n",
    "        \n",
    "        # Display loaded single image:\n",
    "        imgplot_xray = plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "        # Display top class propabilities from single loaded image: \n",
    "        print(\"Label:\", predict_model_label, \"\\n\")        \n",
    "    \n",
    "    if return_prob:\n",
    "        return predict_model_label, new_model_predictions_prob\n",
    "    else:\n",
    "        return predict_model_label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use LIME to explain predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def explain_predictions(model, explainer, x_dataset, nr_samples = None, indecies = None, classes = [\"Normal\", \"Pneumonia\"], num_samples_lime = 1000, num_features_lime = 10, figwidth = 10, figheight = 10):\n",
    "\n",
    "    if (nr_samples is None) and (indecies is None):\n",
    "        return -1\n",
    "    \n",
    "    # Get number of classes:\n",
    "    nr_classes = len(classes)\n",
    "    \n",
    "    # If no indecies are given, select \"nr_samples\" samples:\n",
    "    if indecies is None:\n",
    "        indecies = random.sample(range(x_data.shape[0]), nr_samples)\n",
    "    else:\n",
    "        nr_samples = len(indecies)\n",
    "    \n",
    "    # Set plot height and width:\n",
    "    fig, ax = plt.subplots(nr_samples, nr_classes + 1, sharex='col', sharey='row')\n",
    "    fig.set_figwidth(figwidth)\n",
    "    fig.set_figheight(figheight)\n",
    "                \n",
    "    xs = [np.array(prepare_images_for_model([x]), dtype=np.uint8)[0] for x in x_dataset]\n",
    "\n",
    "    # Get explanations for all selected images:\n",
    "    for j in range(nr_samples):\n",
    "        explanation = explainer.explain_instance(xs[indecies[j]], model.predict, \n",
    "                                                 top_labels=nr_classes, hide_color=0, num_samples=num_samples_lime)\n",
    "\n",
    "        \n",
    "        ax[j,0].imshow(xs[indecies[j]])\n",
    "        ax[j,0].set_title(classes[list(y_data[indecies[j]]).index(max(list(y_data[indecies[j]])))])\n",
    "\n",
    "        xs_pred_label, xs_pred_prob = predict_xray_image(model, xs[indecies[j]], label_list = classes, \n",
    "                                                         display_results = False, return_prob = True)\n",
    "        \n",
    "        for i in range(nr_classes):\n",
    "            temp, mask = explanation.get_image_and_mask(i, positive_only=False, \n",
    "                                                        num_features=num_features_lime, hide_rest=False)\n",
    "\n",
    "            temp = np.array(temp, dtype=np.uint8)\n",
    "\n",
    "            ax[j,i+1].imshow(mark_boundaries(temp, mask))\n",
    "            ax[j,i+1].set_title('p({}) = {:.4f}'.format(classes[i], xs_pred_prob[i]))\n",
    "            \n",
    "            \n",
    "    return fig, ax\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    model.save(model_dir_path + '/' + model_name)  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "def load_model(model_name):\n",
    "    # Returns a compiled model:\n",
    "    model = load_model(model_dir_path + '/' + model_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the images and split them into training and test data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image from \"normal chest xray\" data directory:\n",
    "normal_data_dir = os.path.join(data_dir_path, \"Normal_old\")\n",
    "normal_image_list_full = load_all_images_from_dir(normal_data_dir, (256, 256))\n",
    "\n",
    "# Get list of image from \"Bacterial pneumonia chest xray\" data directory:\n",
    "bacterial_pneumonia_data_dir = os.path.join(data_dir_path, \"Bacterial_Pneumonia_old\")\n",
    "bacterial_pneumonia_image_list_full = load_all_images_from_dir(bacterial_pneumonia_data_dir, (256, 256))\n",
    "\n",
    "# Get list of image from \"Viral pneumonia chest xray\" data directory:\n",
    "viral_pneumonia_data_dir = os.path.join(data_dir_path, \"Viral_Pneumonia_old\")\n",
    "viral_pneumonia_image_list_full = load_all_images_from_dir(viral_pneumonia_data_dir, (256, 256))\n",
    "\n",
    "# Get list of image from \"COVID19 chest xray\" data directory:\n",
    "covid19_data_dir = os.path.join(data_dir_path, \"COVID_19_old\")\n",
    "covid19_image_list_full = load_all_images_from_dir(covid19_data_dir, (256, 256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the lists of diffrent class images:\n",
    "random.shuffle(normal_image_list_full)\n",
    "random.shuffle(bacterial_pneumonia_image_list_full)\n",
    "random.shuffle(viral_pneumonia_image_list_full)\n",
    "random.shuffle(covid19_image_list_full)\n",
    "\n",
    "# Create train-test-split:\n",
    "test_split = 1/3\n",
    "\n",
    "nr_normal_images = len(normal_image_list_full)\n",
    "nr_bacterial_images = len(bacterial_pneumonia_image_list_full)\n",
    "nr_viral_images = len(viral_pneumonia_image_list_full)\n",
    "nr_covid19_images = len(covid19_image_list_full)\n",
    "\n",
    "normal_image_list_full = [normal_image_list_full[:-round(nr_normal_images * test_split)], normal_image_list_full[-round(nr_normal_images * test_split):]]\n",
    "bacterial_pneumonia_image_list_full = [bacterial_pneumonia_image_list_full[:-round(nr_bacterial_images * test_split)], bacterial_pneumonia_image_list_full[-round(nr_bacterial_images * test_split):]]\n",
    "viral_pneumonia_image_list_full = [viral_pneumonia_image_list_full[:-round(nr_viral_images * test_split)], viral_pneumonia_image_list_full[-round(nr_viral_images * test_split):]]\n",
    "covid19_image_list_full = [covid19_image_list_full[:-round(nr_covid19_images * test_split)], covid19_image_list_full[-round(nr_covid19_images * test_split):]]\n",
    "\n",
    "# Combine lists of diffrent class images into single test/train list:\n",
    "train_combined_lists_full = [normal_image_list_full[0], bacterial_pneumonia_image_list_full[0], viral_pneumonia_image_list_full[0], covid19_image_list_full[0]]\n",
    "test_combined_lists_full = [normal_image_list_full[1], bacterial_pneumonia_image_list_full[1], viral_pneumonia_image_list_full[1], covid19_image_list_full[1]]\n",
    "\n",
    "# Get datapoints and labels from images:\n",
    "nr_train_samples = 200\n",
    "x_data, y_data = get_dp_label_pair(train_combined_lists_full, nr_samples = nr_train_samples) \n",
    "\n",
    "nr_test_samples = 100\n",
    "x_test, y_test = get_dp_label_pair(test_combined_lists_full, nr_samples = nr_test_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained models, train them on the training data set and evaluate them on the test data set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained Keras CNNs without the fully connected layer weights (trained on imagenet-data):\n",
    "VGG_model_wo_top = VGG(weights='imagenet', include_top=False)\n",
    "ResNet_model_wo_top = ResNet(weights='imagenet', include_top=False)\n",
    "DenseNet_model_wo_top = DenseNet(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model structure parameters:\n",
    "nr_classes = 4\n",
    "input_shape = (256,256,3)\n",
    "fc_layer_structure = [2048, 2048]\n",
    "\n",
    "# Training parameters:\n",
    "shuffle = True\n",
    "batch_size = 1\n",
    "epochs = 5\n",
    "\n",
    "# Loss parameters:\n",
    "weighted_loss = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = redefine_model_wo_top(model = VGG_model_wo_top, input_shape = input_shape, nr_classes = nr_classes, fc_layer_structure = fc_layer_structure)\n",
    "vgg_model, score = train_model(vgg_model, x_data, y_data, x_test = x_test, y_test = y_test, weighted_loss = weighted_loss, batch_size = batch_size, epochs = epochs, shuffle = shuffle)\n",
    "\n",
    "w_f1_score, roc_auc, class_report, conf_matrix = evaluate_model(vgg_model, x_test, y_test, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"])\n",
    "\n",
    "print(\"\\nWeighted F1-Score:\", w_f1_score, \"; ROC Curve and AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\\n\\n\", class_report)\n",
    "print(\"\\nConfusion Matrix:\\n\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = redefine_model_wo_top(model = ResNet_model_wo_top, input_shape = input_shape, nr_classes = nr_classes, fc_layer_structure = fc_layer_structure)\n",
    "resnet_model, score = train_model(resnet_model, x_data, y_data, x_test = x_test, y_test = y_test, weighted_loss = weighted_loss, batch_size = batch_size, epochs = epochs, shuffle = shuffle)\n",
    "\n",
    "w_f1_score, roc_auc, class_report, conf_matrix = evaluate_model(resnet_model, x_test, y_test, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"])\n",
    "\n",
    "print(\"\\nWeighted F1-Score:\", w_f1_score, \"; ROC Curve and AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\\n\\n\", class_report)\n",
    "print(\"\\nConfusion Matrix:\\n\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model = redefine_model_wo_top(model = DenseNet_model_wo_top, input_shape = input_shape, nr_classes = nr_classes, fc_layer_structure = fc_layer_structure)\n",
    "densenet_model, score = train_model(densenet_model, x_data, y_data, x_test = x_test, y_test = y_test, weighted_loss = weighted_loss, batch_size = batch_size, epochs = epochs, shuffle = shuffle)\n",
    "\n",
    "w_f1_score, roc_auc, class_report, conf_matrix = evaluate_model(densenet_model, x_test, y_test, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"])\n",
    "\n",
    "print(\"\\nWeighted F1-Score:\", w_f1_score, \"; ROC Curve and AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\\n\\n\", class_report)\n",
    "print(\"\\nConfusion Matrix:\\n\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test predictions of each model for an random images from each class: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test_image = random.choice(normal_image_list_full[0]) # Use normal train data set;\n",
    "\n",
    "vgg_prediction = predict_xray_image(vgg_model, normal_test_image, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], display_results = False)\n",
    "resnet_prediction = predict_xray_image(resnet_model, normal_test_image, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], display_results = False)\n",
    "densenet_prediction = predict_xray_image(densenet_model, normal_test_image, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], display_results = False)\n",
    "\n",
    "imgplot_xray = plt.imshow(normal_test_image)\n",
    "plt.title(\"Label: Normal\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Predictions:\\n\")\n",
    "print(\"VGG16:\", vgg_prediction)\n",
    "print(\"ResNet50V2:\", resnet_prediction)\n",
    "print(\"DenseNet121:\", densenet_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacterial_pneumonia_test_image = random.choice(bacterial_pneumonia_image_list_full[0]) # Use bacterial train data set;\n",
    "\n",
    "vgg_prediction = predict_xray_image(vgg_model, bacterial_pneumonia_test_image, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], display_results = False)\n",
    "resnet_prediction = predict_xray_image(resnet_model, bacterial_pneumonia_test_image, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], display_results = False)\n",
    "densenet_prediction = predict_xray_image(densenet_model, bacterial_pneumonia_test_image, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], display_results = False)\n",
    "\n",
    "imgplot_xray = plt.imshow(bacterial_pneumonia_test_image)\n",
    "plt.title(\"Label: Bacterial Pneumonia\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Predictions:\\n\")\n",
    "print(\"VGG16:\", vgg_prediction)\n",
    "print(\"ResNet50V2:\", resnet_prediction)\n",
    "print(\"DenseNet121:\", densenet_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viral_pneumonia_test_image = random.choice(viral_pneumonia_image_list_full[0]) # Use viral train data set;\n",
    "\n",
    "vgg_prediction = predict_xray_image(vgg_model, viral_pneumonia_test_image, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], display_results = False)\n",
    "resnet_prediction = predict_xray_image(resnet_model, viral_pneumonia_test_image, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], display_results = False)\n",
    "densenet_prediction = predict_xray_image(densenet_model, viral_pneumonia_test_image, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], display_results = False)\n",
    "\n",
    "imgplot_xray = plt.imshow(viral_pneumonia_test_image)\n",
    "plt.title(\"Label: Viral Pneumonia\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Predictions:\\n\")\n",
    "print(\"VGG16:\", vgg_prediction)\n",
    "print(\"ResNet50V2:\", resnet_prediction)\n",
    "print(\"DenseNet121:\", densenet_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_pneumonia_test_image = random.choice(covid19_image_list_full[0]) # Use covid train data set;\n",
    "\n",
    "vgg_prediction = predict_xray_image(vgg_model, covid_pneumonia_test_image, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], display_results = False)\n",
    "resnet_prediction = predict_xray_image(resnet_model, covid_pneumonia_test_image, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], display_results = False)\n",
    "densenet_prediction = predict_xray_image(densenet_model, covid_pneumonia_test_image, label_list = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], display_results = False)\n",
    "\n",
    "imgplot_xray = plt.imshow(covid_pneumonia_test_image)\n",
    "plt.title(\"Label: Covid 19\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Predictions:\\n\")\n",
    "print(\"VGG16:\", vgg_prediction)\n",
    "print(\"ResNet50V2:\", resnet_prediction)\n",
    "print(\"DenseNet121:\", densenet_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an explainer (= LIME) on each trained classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LIME-Explainer Instance:\n",
    "explainer = lime_image.LimeImageExplainer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specific indecies:\n",
    "indecies = [150, 350, 550, 750]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Explanations for VGG16-Model:\n",
    "fig, ax = explain_predictions(vgg_model, explainer, x_data, indecies = indecies, classes = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], num_features_lime = 10, num_samples_lime = 10000, figheight = 10, figwidth = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Explanations for ResNet50V2-Model:\n",
    "fig, ax = explain_predictions(resnet_model, explainer, x_data, indecies = indecies, classes = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], num_features_lime = 10, num_samples_lime = 10000, figheight = 10, figwidth = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Explanations for DenseNet121-Model:\n",
    "fig, ax = explain_predictions(densenet_model, explainer, x_data, indecies = indecies, classes = [\"Normal\", \"Bacterial\", \"Viral\", \"Covid\"], num_features_lime = 10, num_samples_lime = 10000, figheight = 10, figwidth = 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store trained model in the model directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Keras-Models:\n",
    "save_model(vgg_model, \"vgg_model.h5\")\n",
    "save_model(resnet_model, \"resnet_model.h5\")\n",
    "save_model(densenet_model, \"densenet_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------\n",
    "# Get list of image from \"normal chest xray\" data directory:\n",
    "normal_data_dir = os.path.join(data_dir_path, \"Normal_old\")\n",
    "images = load_all_images_from_dir(normal_data_dir, (256, 256))[:1]\n",
    "     \n",
    "segment_lung_area(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-GPU",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
